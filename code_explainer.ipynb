{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74f8636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2cd0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e62927",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_promt= \"\"\" \n",
    "                You are a technical explainer and problem-solver.\n",
    "Your job is to answer the user’s technical question with a clear, accurate explanation that matches their skill level.\n",
    "\n",
    "Guidelines:\n",
    "- Start with a short direct answer.\n",
    "- Then explain the concept step-by-step in plain language.\n",
    "- Use a small example when helpful (code, command, or pseudo-code).\n",
    "- Call out assumptions and edge cases.\n",
    "- If the question is ambiguous, ask 1–2 clarifying questions, otherwise make reasonable assumptions and state them.\n",
    "- Be honest about uncertainty; do not invent facts.\n",
    "- Prefer practical guidance over theory unless the user asks for theory.\n",
    "Output format:\n",
    "1) Direct answer\n",
    "2) Explanation\n",
    "3) Example (if useful)\n",
    "4) Common pitfalls / gotchas\n",
    "5) Next steps (optional)\n",
    "\n",
    "Respond in markdown with proper label and sub label without code blocks.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "def get_question_user_prompt(question):\n",
    "    question_user_prompt = \"\"\" Please explain what this code does and why:\n",
    "                                   \\n \"\"\"\n",
    "    question_user_prompt +=question \n",
    "    return question_user_prompt\n",
    "  \n",
    "#           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f7192f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Please explain what this code does and why:\\n                                   \\n  yield from {book.get(\"author\") for book in books if book.get(\"author\")} '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=' yield from {book.get(\"author\") for book in books if book.get(\"author\")} '\n",
    "get_question_user_prompt(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16492ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_code_explainer_ollama(question):\n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_promt},\n",
    "            {\"role\": \"user\", \"content\": get_question_user_prompt(question)}\n",
    "          ],\n",
    "        stream=True  # streanms one by one in chunks (parts)\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Direct Answer\n",
       "This line of code takes the links from a webpage, retrieves them using the `fetch_website_links` function, and appends these links to a string called `user_prompt`.\n",
       "\n",
       "### Explanation\n",
       "Let's break this down step by step:\n",
       "\n",
       "#### Step 1: Fetching Website Links\n",
       "The `fetch_website_links(url)` function is used to extract the links from a given URL. This could be done using web scraping techniques.\n",
       "\n",
       "#### Step 2: Retrieving the Links\n",
       "The retrieved links are stored in a list called `links`.\n",
       "\n",
       "#### Step 3: Appending Links to User Prompt\n",
       "A string called `user_prompt` is updated by appending the joined links to it. The `.join()` method concatenates all elements in the `links` list into a single string.\n",
       "\n",
       "Assumptions:\n",
       "\n",
       "* The `fetch_website_links(url)` function returns a list of tuples where each tuple contains the link and other information like title.\n",
       "* The `user_prompt` variable is initialized as an empty string.\n",
       "\n",
       "### Example\n",
       "\n",
       "```python\n",
       "# fetch_website_links function is not shown here, but it would look something like this:\n",
       "def fetch_website_links(url):\n",
       "    import requests\n",
       "    # send HTTP request to url and parse the HTML content\n",
       "    response = requests.get(url)\n",
       "    links = []\n",
       "    for line in response.text.split('<a href=\"'):\n",
       "        link, title = line.strip().split('\">')\n",
       "        links.append((link, title))\n",
       "    return links\n",
       "\n",
       "# sample usage with fetch_website_links and append links to user_prompt\n",
       "url = \"https://www.example.com\"\n",
       "links = fetch_website_links(url)\n",
       "user_prompt += \". \".join([link for link, _ in links])  # getting just the link part\n",
       "```\n",
       "\n",
       "### Common Pitfalls / Gotchas\n",
       "\n",
       "* Make sure `fetch_website_links(url)` returns a list of strings (the actual link) instead of a different data type.\n",
       "* If there are multiple links on each page with the same suffix, how do you distinguish between them? This may require more complex web scraping techniques."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "stream_code_explainer_ollama(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed1d8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Direct Answer**\n",
       "The code reads links from a website using the `fetch_website_links` function, concatenates them into a single string, and appends them to the `user_prompt` variable.\n",
       "\n",
       "**Explanation**\n",
       "Let's break down what's happening in this code:\n",
       "\n",
       "1. **Fetching links**: The `fetch_website_links` function is called with a URL argument (`url`). This function likely sends an HTTP request to the website, parses its HTML content, and extracts URLs (i.e., links) from it.\n",
       "2. **Concatenating links**: The returned list of links (`links`) is then converted into a single string using the `.join()` method. The string contains all the link values separated by spaces.\n",
       "3. **Appending to user prompt**: The resulting concatenated links string (`user_prompt`) is appended (i.e., added) to `user_prompt` itself.\n",
       "\n",
       "**Assumptions**\n",
       "We assume that:\n",
       "\n",
       "* The `fetch_website_links` function is defined elsewhere in the codebase and returns a list of URLs.\n",
       "* `url` contains a valid website URL.\n",
       "* `user_prompt` is an existing variable or attribute initialized earlier in the code.\n",
       "\n",
       "**Common Pitfalls / Gotchas**\n",
       "Be cautious when dealing with link parsing, as some websites use complex structures or scripts to generate links. Also, ensure that the `fetch_website_links` function respects any rate limits, redirects, or other website-specific constraints.\n",
       "\n",
       "**Example (Pseudo-Code)**\n",
       "```\n",
       "links = fetch_website_links(\"https://example.com\")\n",
       "user_prompt = \"\"\n",
       "if links:\n",
       "    user_prompt = (\n",
       "        \"Visit these websites:\\n\"\n",
       "        + \"\\n\".join(links)\n",
       "    )\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question=\"\"\"\"week1 EXERCISE.ipynb\"links = fetch_website_links(url)\n",
    "           user_prompt += \"\\n\".join(links) \"\"\"\n",
    "stream_code_explainer_ollama(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de2781",
   "metadata": {},
   "source": [
    "### Adding UI using gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d317f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LLM\\Projects\\LLM-Code-Explainer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84adc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_code(s: str) -> bool:\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return False\n",
    "\n",
    "    patterns = [\n",
    "        r\"```\",                          # fenced code blocks\n",
    "        r\"^\\s{4,}\\S\",                    # indented lines (4+ spaces)\n",
    "        r\"\\b(def|class|import|from|if|elif|else|for|while|try|except|with|return|print)\\b\",\n",
    "        r\"[(){}\\[\\];]\",                  # code punctuation\n",
    "        r\"==|!=|<=|>=|:=|\\+=|-=|\\*=|/=|//=|\\*\\*\",\n",
    "        r\":\\s*$\",                        # line ending with colon (Python blocks)\n",
    "        r\"#\",                            # comment\n",
    "    ]\n",
    "\n",
    "    score = sum(bool(re.search(p, s, re.MULTILINE)) for p in patterns)\n",
    "    if score >= 2:\n",
    "        likely_code=True\n",
    "    else:\n",
    "        likely_code=False\n",
    "\n",
    "    return likely_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c05e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_explainer_ollama(message,history):\n",
    "    history=[{\"role\":h['role'],\"content\":h['content']}for h in history]\n",
    "    if looks_like_code(message)==True:\n",
    "        relative_system_promt=system_promt\n",
    "        relative_user_prompt=get_question_user_prompt(message)\n",
    "    else:\n",
    "        relative_system_promt='You are an polite helpful Technical assistant to help learners'\n",
    "        relative_user_prompt=message\n",
    "        \n",
    "    \n",
    "    stream = ollama.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[{\"role\": \"system\", \"content\": relative_system_promt}] +history+\n",
    "          [{\"role\": \"user\", \"content\": relative_user_prompt}],\n",
    "        stream=True  # streanms one by one in chunks (parts)\n",
    "    )    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d38f8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://eca2cf54197257aca8.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eca2cf54197257aca8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat=gr.ChatInterface(fn=generate_code_explainer_ollama,title='Code Explainer')\n",
    "chat.launch(share=True,inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9cad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-explaine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
